{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para importar la base de datos leucemia\n",
    "from sklearn.datasets.mldata import fetch_mldata\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Para Procesamiento de datos\n",
    "## Regresion logistica\n",
    "from sklearn.linear_model import LogisticRegression   #Importa las fxn de validacion cruzadas\n",
    "from sklearn.cross_validation import train_test_split #Importa las funciones de validación cruzada\n",
    "from sklearn.preprocessing import StandardScaler      #Importar las funciones de preparacion \n",
    "## Naive bayes\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB #importar libreria del clasificador \n",
    "## Clustering\n",
    "# K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import cluster\n",
    "## GMM\n",
    "from matplotlib import patches # es para hacer elipses\n",
    "from sklearn import datasets\n",
    "from sklearn.mixture import GMM #mixture contiene los modelos de mezclas\n",
    "from sklearn.cross_validation import StratifiedKFold #validación por K-folds\n",
    "## Arboles \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_home = tempfile.mkdtemp()\n",
    "leuk = fetch_mldata('leukemia', transpose_data=True, data_home=test_data_home)\n",
    "\n",
    "X = leuk['data']\n",
    "\n",
    "y = leuk['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Supervisados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las muestras mal clasificadas fueron de 21/22 \n",
      "\n",
      "######################################################################\n",
      "\n",
      " Desempeño del clasificador sobre el conjunto de entrenamiento \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       1.00      1.00      1.00        16\n",
      "Segunda Clase       1.00      1.00      1.00        34\n",
      "\n",
      "  avg / total       1.00      1.00      1.00        50\n",
      "\n",
      "######################################################################\n",
      "\n",
      "\n",
      "######################################################################\n",
      "Desempeño del clasificador sobre el conjunto de la validación \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       0.90      1.00      0.95         9\n",
      "Segunda Clase       1.00      0.92      0.96        13\n",
      "\n",
      "  avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "#__________________________________ Preprocesamiento de datos ___________________________________#\n",
    "clasificador = LogisticRegression(C=1000.0,random_state=0) # C es el parametro\n",
    "clasificador.fit(x_norm_train, y_train) # entrenamiento del clasificador\n",
    "\n",
    "# para validar el clasificador\n",
    "y_pred = clasificador.predict(x_norm_test)\n",
    "\n",
    "print('Las muestras mal clasificadas fueron de %d/%d '%((y_test == y_pred).sum(),len(y_pred)))\n",
    "\n",
    "validar_clasificador(y_train,X_train,clasificador,y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las muestras mal clasificadas fueron de 22/22 \n",
      "\n",
      "######################################################################\n",
      "\n",
      " Desempeño del clasificador sobre el conjunto de entrenamiento \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       1.00      1.00      1.00        16\n",
      "Segunda Clase       1.00      1.00      1.00        34\n",
      "\n",
      "  avg / total       1.00      1.00      1.00        50\n",
      "\n",
      "######################################################################\n",
      "\n",
      "\n",
      "######################################################################\n",
      "Desempeño del clasificador sobre el conjunto de la validación \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       0.90      1.00      0.95         9\n",
      "Segunda Clase       1.00      0.92      0.96        13\n",
      "\n",
      "  avg / total       0.96      0.95      0.95        22\n",
      "\n",
      "\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "#____________________________ Naive Bayes ____________________________________#\n",
    "\n",
    "#generar el clasificador\n",
    "clasificador = GaussianNB() #instanciamos y luego entrenamos\n",
    "clasificador.fit(x_norm_train, y_train) #entrenamos el clasificador\n",
    "\n",
    "#hacer la predicion\n",
    "y_predict = clasificador.predict(x_norm_test)\n",
    "\n",
    "print('Las muestras mal clasificadas fueron de %d/%d '%((y_test == y_predict).sum(),len(y_predict)))\n",
    "\n",
    "\n",
    "validar_clasificador(y_train,X_train,clasificador,y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje No Supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas con Clustering : \n",
      "______________________________________________________________________________\n",
      "[1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1]\n",
      "Etiquetas originales: \n",
      "______________________________________________________________________________\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1 -1\n",
      " -1 -1 -1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1]\n",
      "______________________________________________________________________________\n",
      "[ 1  1  1  1  1 -1 -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1 -1 -1  1 -1\n",
      "  1 -1  1 -1  1 -1  1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1\n",
      " -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1 -1  1]\n",
      "El porcentaje de muestras bien clasificadas es de :  41.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "#__________________________ K-Means ______________________________________#\n",
    "\n",
    "# definimos el número de clusters o grupos\n",
    "num_cluster = 2\n",
    "#generamos el modelo \n",
    "\n",
    "#init establece el método de localizacion inicial de los centroides\n",
    "modelo_kmeans= KMeans(init = 'k-means++',n_clusters = num_cluster, n_init=10)\n",
    "\n",
    "#entrenar el modelo \n",
    "modelo_kmeans.fit(X)\n",
    "\n",
    "#centros\n",
    "centroides = modelo_kmeans.cluster_centers_\n",
    "\n",
    "labels = modelo_kmeans.labels_ \n",
    "print('Etiquetas con Clustering : ')\n",
    "print('______________________________________________________________________________')\n",
    "print(labels)\n",
    "print('Etiquetas originales: ')\n",
    "print('______________________________________________________________________________')\n",
    "print(y)\n",
    "clase_0 = 0\n",
    "clase_1 = 0\n",
    "\n",
    "labels_t = np.where(labels==0,-1,labels)\n",
    "print('______________________________________________________________________________')\n",
    "print(labels_t)\n",
    "cont = 0\n",
    "for i in range(len(labels)):\n",
    "    if labels_t[i] == labels[i]:\n",
    "        cont = cont + 1\n",
    "val = (cont/len(labels))*100\n",
    "print('El porcentaje de muestras bien clasificadas es de : ',val,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de mezclas Gaussianas GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:52: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El acierto de entrenamiento es del  100.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El acierto de entrenamiento es del  100.0 %\n",
      "\n",
      "######################################################################\n",
      "\n",
      " Desempeño del clasificador sobre el conjunto de entrenamiento \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       1.00      1.00      1.00        20\n",
      "Segunda Clase       1.00      1.00      1.00        37\n",
      "\n",
      "  avg / total       1.00      1.00      1.00        57\n",
      "\n",
      "######################################################################\n",
      "\n",
      "\n",
      "######################################################################\n",
      "Desempeño del clasificador sobre el conjunto de la validación \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       1.00      1.00      1.00         5\n",
      "Segunda Clase       1.00      1.00      1.00        10\n",
      "\n",
      "  avg / total       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "y_respaldo = y\n",
    "y_respaldo = np.where(y_respaldo==-1,0,y_respaldo)\n",
    "\n",
    "#print(y_respaldo)\n",
    "\n",
    "#realizamos las particiones de los datos para entrenamiento y validacion 80/20\n",
    "indices = StratifiedKFold(y_respaldo, n_folds = 5)\n",
    "\n",
    "#objetos iterables para sacar los indices\n",
    "train_index,test_index = next(iter(indices))\n",
    "\n",
    "#extraer los datos del contenido de iris\n",
    "X_train = X[train_index]\n",
    "y_train = y_respaldo[train_index]\n",
    "X_test = X[test_index]\n",
    "y_test = y_respaldo[test_index]\n",
    "\n",
    "\n",
    "#calculamos el número de clases\n",
    "numero_clases = len(np.unique(y_train))\n",
    "\n",
    "# Construir el clasificador GMM\n",
    "clasificador = GMM(n_components = numero_clases, covariance_type = 'full', init_params = 'w', n_iter = 20)\n",
    "\n",
    "clasificador.means_ = np.array([X_train[y_train==i].mean(axis=0)for i in range(numero_clases)])\n",
    "\n",
    "\n",
    "#Entrenamos con fit\n",
    "clasificador.fit(X_train)\n",
    "y_train_predict = clasificador.predict(X_train)\n",
    "acc_train = np.mean(y_train_predict.ravel() == y_train.ravel())*100\n",
    "print('El acierto de entrenamiento es del ',acc_train,'%')\n",
    "\n",
    "y_test_predict = clasificador.predict(X_test)\n",
    "acc_test = np.mean(y_test_predict.ravel() == y_test.ravel())*100\n",
    "print('El acierto de entrenamiento es del ',acc_test,'%')\n",
    "\n",
    "# Reporte de validación\n",
    "validar_clasificador(y_train,X_train,clasificador,y_test,y_test_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arboles de decisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "\n",
      " Desempeño del clasificador sobre el conjunto de entrenamiento \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       1.00      1.00      1.00        19\n",
      "Segunda Clase       1.00      1.00      1.00        35\n",
      "\n",
      "  avg / total       1.00      1.00      1.00        54\n",
      "\n",
      "######################################################################\n",
      "\n",
      "\n",
      "######################################################################\n",
      "Desempeño del clasificador sobre el conjunto de la validación \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       1.00      0.83      0.91         6\n",
      "Segunda Clase       0.92      1.00      0.96        12\n",
      "\n",
      "  avg / total       0.95      0.94      0.94        18\n",
      "\n",
      "\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "# Separamos los datos de acuerdo a las etiquetas(2 clases\n",
    "clase1 = np.array(X[y==1])\n",
    "clase_1 = np.array(X[y==-1])\n",
    "\n",
    "# Dividimos los datos en entrenamiento y validación\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y, test_size = 0.25, random_state = 5)\n",
    "\n",
    "# construimos el clasificador\n",
    "# variable tipo diccionario con los parametros del arbol\n",
    "# random state: semilla con la que arranca las cosas aleatorias\n",
    "# max_depth: Numero de niveles del arbolito.\n",
    "parametros = {'random_state' : 0, 'max_depth':4}\n",
    "#construir arbol de clasificación\n",
    "clasificador = DecisionTreeClassifier(**parametros)\n",
    "\n",
    "# lo entrenamos para que con el conjunto de entrenamiento se arme el arbolito\n",
    "clasificador.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = clasificador.predict(X_test)\n",
    "\n",
    "validar_clasificador(y_train,X_train,clasificador,y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bosques aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "\n",
      " Desempeño del clasificador sobre el conjunto de entrenamiento \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       1.00      1.00      1.00        19\n",
      "Segunda Clase       1.00      1.00      1.00        35\n",
      "\n",
      "  avg / total       1.00      1.00      1.00        54\n",
      "\n",
      "######################################################################\n",
      "\n",
      "\n",
      "######################################################################\n",
      "Desempeño del clasificador sobre el conjunto de la validación \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Primera Clase       1.00      1.00      1.00         6\n",
      "Segunda Clase       1.00      1.00      1.00        12\n",
      "\n",
      "  avg / total       1.00      1.00      1.00        18\n",
      "\n",
      "\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tipo_clasificador = 'ba'\n",
    "\n",
    "parametros = { 'n_estimators':100, 'max_depth': 4, 'random_state':0}\n",
    "\n",
    "if tipo_clasificador == 'ba':\n",
    "    # Bosque aleatorio\n",
    "    clasificador = RandomForestClassifier(**parametros)\n",
    "else:\n",
    "    # Bosque extra aleatorio\n",
    "    clasificador = ExtraTreesClassifier(**parametros)\n",
    "\n",
    "# Entrenamos el clasificador\n",
    "clasificador.fit(X_train, y_train)\n",
    "\n",
    "#validamos el clasificador\n",
    "y_test_pred = clasificador.predict(X_test)\n",
    "\n",
    "\n",
    "## REPORTE DE CLASIFICACIÓN\n",
    "validar_clasificador(y_train,X_train,clasificador,y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validar_clasificador(y_train,X_train,clasificador,y_test,y_predict):\n",
    "    # Evaluamos el desempeño del clasificador imprimiendo el reporte de clasificación.\n",
    "    nombres_clases = ['Primera Clase','Segunda Clase']\n",
    "    print('\\n' + '#'*70)\n",
    "    print('\\n Desempeño del clasificador sobre el conjunto de entrenamiento \\n')\n",
    "    print(classification_report(y_train, clasificador.predict(X_train), target_names = nombres_clases))\n",
    "    print('#'*70 + '\\n')\n",
    "    print('\\n'+ '#'*70 )\n",
    "    print('Desempeño del clasificador sobre el conjunto de la validación \\n')\n",
    "    print(classification_report(y_test,y_predict, target_names = nombres_clases))\n",
    "    print('\\n'+ '#'*70 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remocion de la media\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.3, random_state = 3)\n",
    "\n",
    "#Remoción para x_train\n",
    "def Remocion(X):\n",
    "    med = X.mean(axis=0)\n",
    "    des = X.std(axis=0)\n",
    "    X = X - med\n",
    "    X = X/des\n",
    "    return X,med, des\n",
    "\n",
    "#Remocion para x_test\n",
    "def Remocion_test(X,med,des):\n",
    "    X = X - med\n",
    "    X = X/des\n",
    "    return X\n",
    "\n",
    "#Remocion para x_train\n",
    "x_norm_train,t_train_mean,t_train_desv = Remocion(X_train)\n",
    "#Remocion para x_test\n",
    "x_norm_test = Remocion_test(X_test,t_train_mean,t_train_desv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
